{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3bskVXPvchm"
   },
   "source": [
    "# Hello, Deep Learning Reading Group\n",
    "## A curated version of TF tutorials 1 & 2\n",
    "### Archy de Berker & Zeb Kurth-Nelson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rb5rSpcZvYbX"
   },
   "source": [
    "\n",
    "When you think of doing things in TensorFlow, you might want to think of creating tensors (like matrices), adding operations (that output other tensors), and then executing the computation (running the computational graph). \n",
    "\n",
    "In particular, it's important to realize that when you add an operation on tensors, it doesn't execute immediately.\n",
    "\n",
    "Rather, TensorFlow waits for you to define all the operations you want to perform. Then, TensorFlow optimizes the computation graph, deciding how to execute the computation, before generating the data. Because of this, a tensor in TensorFlow isn't so much holding the data as a placeholder for holding the data, waiting for the data to arrive when a computation is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8FhiMivhcYB"
   },
   "source": [
    "## Adding two vectors in TensorFlow\n",
    "\n",
    "Let's start with something that should be simple. Let's add two length four vectors (two 1st-order tensors):\n",
    "\n",
    "$\\begin{bmatrix} 1. & 1. & 1. & 1.\\end{bmatrix} + \\begin{bmatrix} 2. & 2. & 2. & 2.\\end{bmatrix} = \\begin{bmatrix} 3. & 3. & 3. & 3.\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1446243605678,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "7391995727249e65",
      "userId": "106975671469698476657"
     },
     "user_tz": 420
    },
    "id": "2iv3XQ6k3eF1",
    "outputId": "e21e1144-736a-4b1f-df78-a9ceab9d4c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "input2 = tf.constant([2.0, 2.0, 2.0, 2.0])\n",
    "output = tf.add(input1, input2)\n",
    "\n",
    "\n",
    "with tf.Session():\n",
    "  result = output.eval()\n",
    "  \n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqLV5GXT3wLy"
   },
   "source": [
    "What we're doing is creating two vectors, [1.0, 1.0, 1.0, 1.0] and [2.0, 2.0, 2.0, 2.0], and then adding them. Note that we actually have to use the tf function **tf.add** to do this - we can't just use +.\n",
    "\n",
    "We can do a similar thing using the very commonly utilised python package numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1446242021921,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "7391995727249e65",
      "userId": "106975671469698476657"
     },
     "user_tz": 420
    },
    "id": "MDWJf0lHAF4E",
    "outputId": "66d8c4a2-92b7-4048-b365-39dc42dff2bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.] + [ 2.  2.  2.  2.] = [ 3.  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x, y = np.full(4, 1.0), np.full(4, 2.0)\n",
    "print \"{} + {} = {}\".format(x, y, x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we wanted matrices instead of vectors, the same syntax applies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]] + [[ 2.  2.]\n",
      " [ 2.  2.]\n",
      " [ 2.  2.]\n",
      " [ 2.  2.]] = [[ 3.  3.]\n",
      " [ 3.  3.]\n",
      " [ 3.  3.]\n",
      " [ 3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x, y = np.full([4,2], 1.0), np.full([4,2], 2.0)\n",
    "print \"{} + {} = {}\".format(x, y, x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing to note for those coming from matlab: python isn't build primarily for doing maths. If you forget this and try to add, subtract, and multiply things in a laissez-faire manner, things go wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[1, 2, 3, 4]\n",
      "b=\n",
      "[5, 6, 7, 8]\n",
      "c=\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7, 8]\n",
    "c = a+b\n",
    "\n",
    "print \"a=\"\n",
    "print a \n",
    "print \"b=\" \n",
    "print b\n",
    "print \"c=\" \n",
    "print c\n",
    "\n",
    "print type(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the default type when you just stick things in square brackets is NOT a numerical vector - it's a list. And when you use the + operation, it doesn't ADD your vectors - it CONCATENATES your list!\n",
    "\n",
    "By  now you've noticed that there are three basic kinds of things we've been dealing with: native Python objects (like a = [1, 2, 3, 4]), numpy objects (like x = np.full(4, 1.0)), and TensorFlow objects (like input1 = tf.constant([1.0, 1.0, 1.0, 1.0])).\n",
    "\n",
    "Coming back to TensorFlow objects, these kind of objects are actually smart enough to understand that the + operator should mean vector addition, so we don't need to use tf.add() as we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "input2 = tf.constant([2.0, 2.0, 2.0, 2.0])\n",
    "output =input1+ input2\n",
    "\n",
    "with tf.Session():\n",
    "  result = output.eval()\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I52jQOyO8vAn"
   },
   "source": [
    "## Details of adding two vectors in TensorFlow\n",
    "\n",
    "The example above of adding two vectors involves a lot more than it seems, so let's look at it in more depth.\n",
    "\n",
    ">`import tensorflow as tf`\n",
    "\n",
    "This import brings TensorFlow's public API into our IPython runtime environment.\n",
    "\n",
    ">`with tf.Session():`\n",
    "\n",
    "When you run an operation in TensorFlow, you need to do it in the context of a `Session`. \n",
    "\n",
    "A session holds the **computation graph**, which contains the tensors and the operations. When you create tensors and operations, they are not executed immediately, but wait for other operations and tensors to be added to the graph, only executing when finally requested to produce the results of the session. Deferring the execution like this provides additional opportunities for parallelism and optimization, as TensorFlow can decide how to combine operations and where to run them after TensorFlow knows about all the operations. \n",
    "\n",
    ">>`input1 = tf.constant([1.0, 1.0, 1.0, 1.0])`\n",
    "\n",
    ">>`input2 = tf.constant([2.0, 2.0, 2.0, 2.0])`\n",
    "\n",
    "The next two lines create tensors using a convenience function called `constant`, which is similar to numpy's `array` and numpy's `full`. If you look at the code for `constant`, you can see the details of what it is doing to create the tensor. In summary, it creates a tensor of the necessary shape and applies the constant operator to it to fill it with the provided values. The values to `constant` can be Python or numpy arrays. `constant` can take an optional shape parameter, which works similarly to numpy's `fill` if provided, and an optional name parameter, which can be used to put a more human-readable label on the operation in the TensorFlow operation graph.\n",
    "\n",
    ">>`output = tf.add(input1, input2)`\n",
    "\n",
    "You might think `add` just adds the two vectors now, **but it doesn't quite do that**. What it does is put the `add` operation **into the computational graph**. The results of the addition aren't available yet. They've been put in the computation graph, but the computation graph hasn't been executed yet.\n",
    "\n",
    ">>`result = output.eval()`\n",
    "\n",
    ">>`print result`\n",
    "\n",
    "`eval()` is also slightly more complicated than it looks. Yes, it does get the value of the vector (tensor) that results from the addition. It returns this as a numpy array, which can then be printed. But, it's important to realize it also **runs the computation graph at this point, because we demanded the output from the operation node of the graph; to produce that, it had to run the computation graph**. So, this is the point where the addition is actually performed, not when `add` was called, as `add` just put the addition operation into the TensorFlow computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concept 1: Tensorflow operations aren't performed until the Tensorflow session is evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zszjoYUjkUNU"
   },
   "source": [
    "##  Adding two matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWNYBCB6kbri"
   },
   "source": [
    "Next, let's do something very similar, adding two matrices:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "  1. & 1. & 1. \\\\\n",
    "  1. & 1. & 1. \\\\\n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    "  1. & 2. & 3. \\\\\n",
    "  4. & 5. & 6. \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "  2. & 3. & 4. \\\\\n",
    "  5. & 6. & 7. \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1446242690334,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "7391995727249e65",
      "userId": "106975671469698476657"
     },
     "user_tz": 420
    },
    "id": "tmWcCxSilYkg",
    "outputId": "f3a2e904-790b-42e1-9ca4-2f3c54d7f4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n",
      "[[-2. -1.  0.]\n",
      " [ 1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "input1 = tf.constant(-3.0, shape=[2, 3])\n",
    "input2 = tf.constant(np.reshape(np.arange(1.0, 7.0, dtype=np.float32), (2, 3)))\n",
    "output = tf.add(input1, input2)\n",
    "  \n",
    "with tf.Session():\n",
    "  print input2.eval()\n",
    "  print output.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new operations that we're introducing here:\n",
    "\n",
    "  *np.reshape* : this takes a vector, and applies the shape argument to it, much like in matlab\n",
    "  \n",
    "  *np.arange*  : this produces a range of numbers (like matlab 1:n). But (oddly, in our opinion), it includes the FIRST value but not the LAST.\n",
    "  This is because python uses zero based indexing ([0] refers to the first item in the array) and if we start from zero, then the second argument would tell us *how many* items we'll get.\n",
    "  \n",
    "  So we get the numbers 1-6. When we add the constant -3 to each element of the matrix, we end up with -2 through +3. We can also specify the *type* here (like float32). This is important, because we will struggle later on if our numbers end up in different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuU3Bmglq1vd"
   },
   "source": [
    "## Task 1: Modify the above code to do multiplication of a weights matrix with some inputs to produce an output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should use the tensorflow command **tf.matmul** to do the multiplication, and **np.random.randn** to initialise your weights matrix with randomweights.\n",
    "\n",
    "Try using a placeholder variable to give you an adjustable number of features (i.e. the length of the input, and the first dimension of the weights matrix).\n",
    "\n",
    "At the end, print out your inputs and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put your answer here (HINT: should look very similar to the code just above, but using multiplication instead of addition)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDAVTPhb22AP"
   },
   "source": [
    "What we have here is a one-layer linear neural network. This could be trained to match some function if we adjusted the weights based on some examples of inputs and outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhnBjAUILuy8"
   },
   "source": [
    "## Use of variables\n",
    "\n",
    "Let's look at adding two small matrices in a loop, not by creating new tensors every time, but by updating the existing values and then re-running the computation graph on the new data. \n",
    "\n",
    "This happens a lot with machine learning models, where we change some parameters each time such as gradient descent on some weights and then perform the same computations over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1446244201894,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "7391995727249e65",
      "userId": "106975671469698476657"
     },
     "user_tz": 420
    },
    "id": "vJ_AgZ8lLtRv",
    "outputId": "8d3aadaa-2b34-4642-889b-e3daaf5ee693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95963669 -0.43129063]] [[ 0.95963669 -0.43129063]]\n",
      "[[-0.97799993  0.46899056]] [[-0.01836324  0.03769994]]\n",
      "[[ 0.68374348  0.17845488]] [[ 0.66538024  0.21615481]]\n",
      "[[ 0.90204906 -0.432796  ]] [[ 1.5674293  -0.21664119]]\n",
      "[[ 0.36887693  0.68009949]] [[ 1.93630624  0.4634583 ]]\n"
     ]
    }
   ],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set up two variables, total and weights, that we'll change repeatedly.\n",
    "total = tf.Variable(tf.zeros([1,2])) \n",
    "weights = tf.Variable(tf.zeros([1,2]))  # these values won't actually be used, but we have to initialize the Variable.\n",
    "\n",
    "# This only adds the operators to the graph right now. The assignment\n",
    "# and addition operations are not performed yet.\n",
    "update_weights = tf.assign(weights, tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "update_total = tf.assign(total, tf.add(total, weights))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Initialize the variables we defined above.\n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  for _ in range(5):\n",
    "    # Actually run the operation graph, so randomly generate weights and then\n",
    "    # add them into the total. Order does matter here. We need to update\n",
    "    # the weights before updating the total.\n",
    "    sess.run(update_weights)\n",
    "    sess.run(update_total)\n",
    "    \n",
    "    print weights.eval(), total.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concept 2: 'Variables' in TF have a special meaning: they're things that we're going to repeatedly give new values to, using the command 'assign' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSYJr89aM_n0"
   },
   "source": [
    "Starting off, the code creates two variables, `total` and `weights`. `total` is initialized to \\[0, 0\\]. Meanwhile, `weights` will be set to new random values between -1 and 1, every time we go through the loop and call sess.run(update_weights).\n",
    "\n",
    "Next, two assignment operators are added to the graph, one that updates weights with random values from [-1, 1], the other that updates the total with the new weights. Again, the operators are not executed here. In fact, this isn't even inside the loop. We won't execute these operations until the `eval` call inside the loop.\n",
    "\n",
    "Finally, in the for loop, we run each of the operators. In each iteration of the loop, this executes the operators we added earlier, first putting random values into the weights, then updating the totals with the new weights. This call uses `eval` on the session; the code also could have called `eval` on the operators (e.g. `update_weights.eval`).\n",
    "\n",
    "It can be a little hard to wrap your head around exactly what computation is done when. The important thing to remember is that computation is only performed on demand.\n",
    "\n",
    "Variables can be useful in cases where you have a large amount of computation and data that you want to use over and over again with just a minor change to the input each time. That happens quite a bit with neural networks, for example, where you just want to update the weights each time you go through the batches of input data, then run the same operations over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fL3WfAbKzqr5"
   },
   "source": [
    "# Task 2: The code below runs a simple model, where we find a weight which scales the input to match a target. We also give you some code for plotting. Combine them to plot the progress of the model towards convergence. You may want to fiddle with the learning rate and number of iterations to get pretty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb870359e50>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb85cd5a110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.scatter(np.random.random([100,1]),np.random.random([100,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.95002389] [ 0.16185382] [ 0.15376499] [ 0.19043355] [-0.03666855]\n",
      "[ 0.95002389] [ 0.16552067] [ 0.15724859] [ 0.19043355] [-0.03318496]\n",
      "[ 0.95002389] [ 0.16883916] [ 0.16040123] [ 0.19043355] [-0.03003232]\n",
      "[ 0.95002389] [ 0.1718424] [ 0.16325438] [ 0.19043355] [-0.02717917]\n",
      "[ 0.95002389] [ 0.17456031] [ 0.16583647] [ 0.19043355] [-0.02459708]\n",
      "[ 0.95002389] [ 0.17702001] [ 0.16817324] [ 0.19043355] [-0.02226031]\n",
      "[ 0.95002389] [ 0.17924604] [ 0.17028801] [ 0.19043355] [-0.02014554]\n",
      "[ 0.95002389] [ 0.18126059] [ 0.17220189] [ 0.19043355] [-0.01823166]\n",
      "[ 0.95002389] [ 0.18308376] [ 0.17393394] [ 0.19043355] [-0.01649961]\n",
      "[ 0.95002389] [ 0.18473372] [ 0.17550145] [ 0.19043355] [-0.0149321]\n",
      "[ 0.95002389] [ 0.18622693] [ 0.17692004] [ 0.19043355] [-0.01351351]\n",
      "[ 0.95002389] [ 0.18757829] [ 0.17820385] [ 0.19043355] [-0.0122297]\n",
      "[ 0.95002389] [ 0.18880126] [ 0.17936571] [ 0.19043355] [-0.01106784]\n",
      "[ 0.95002389] [ 0.18990804] [ 0.18041718] [ 0.19043355] [-0.01001637]\n",
      "[ 0.95002389] [ 0.19090968] [ 0.18136875] [ 0.19043355] [-0.00906479]\n",
      "[ 0.95002389] [ 0.19181617] [ 0.18222994] [ 0.19043355] [-0.00820361]\n",
      "[ 0.95002389] [ 0.19263652] [ 0.1830093] [ 0.19043355] [-0.00742425]\n",
      "[ 0.95002389] [ 0.19337894] [ 0.18371461] [ 0.19043355] [-0.00671893]\n",
      "[ 0.95002389] [ 0.19405083] [ 0.18435293] [ 0.19043355] [-0.00608061]\n",
      "[ 0.95002389] [ 0.19465889] [ 0.18493059] [ 0.19043355] [-0.00550295]\n",
      "[ 0.95002389] [ 0.19520919] [ 0.1854534] [ 0.19043355] [-0.00498015]\n",
      "[ 0.95002389] [ 0.1957072] [ 0.18592651] [ 0.19043355] [-0.00450704]\n",
      "[ 0.95002389] [ 0.1961579] [ 0.1863547] [ 0.19043355] [-0.00407885]\n",
      "[ 0.95002389] [ 0.19656579] [ 0.1867422] [ 0.19043355] [-0.00369135]\n",
      "[ 0.95002389] [ 0.19693492] [ 0.18709289] [ 0.19043355] [-0.00334066]\n",
      "[ 0.95002389] [ 0.19726899] [ 0.18741025] [ 0.19043355] [-0.0030233]\n",
      "[ 0.95002389] [ 0.19757132] [ 0.18769747] [ 0.19043355] [-0.00273608]\n",
      "[ 0.95002389] [ 0.19784492] [ 0.18795741] [ 0.19043355] [-0.00247614]\n",
      "[ 0.95002389] [ 0.19809254] [ 0.18819264] [ 0.19043355] [-0.00224091]\n",
      "[ 0.95002389] [ 0.19831663] [ 0.18840554] [ 0.19043355] [-0.002028]\n"
     ]
    }
   ],
   "source": [
    "# Target-matching model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# we have a single input\n",
    "print \n",
    "input     = tf.constant(np.random.random([1]).astype(np.float32))\n",
    "target    = tf.constant(np.random.random([1]).astype(np.float32))\n",
    "\n",
    "alpha     = tf.constant([0.1])\n",
    "nIters    = 30\n",
    "\n",
    "totalTrack = np.zeros([nIters,1])\n",
    "# Set up two variables, total and weights, that we'll change repeatedly.\n",
    "\n",
    "weights = tf.Variable(tf.random_uniform([1]))\n",
    "total   = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "\n",
    "# This only adds the operators to the graph right now. The assignment\n",
    "# and addition operations are not performed yet.\n",
    "update_total = tf.assign(total, tf.mul(input, weights))\n",
    "update_weights = tf.assign(weights, weights-(alpha*(total-target)))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "  # Initialize the variables we defined above.\n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  for _ in range(nIters):\n",
    "    # Actually run the operation graph, so randomly generate weights and then\n",
    "    # add them into the total. Order does matter here. We need to update\n",
    "    # the weights before updating the total.\n",
    "    sess.run(update_weights)\n",
    "    sess.run(update_total)\n",
    "    \n",
    "    totalTrack[_]=total.eval()\n",
    "    \n",
    "    print input.eval(),weights.eval(), total.eval(), target.eval(), total.eval()-target.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb84affb910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.plot(np.arange(1,nIters+1),totalTrack)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "  plt.plot(np.arange(1,nIters+1),np.full([nIters,1],target.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top tips for this section:\n",
    "\n",
    "- It's important to get your types matching. The default for TF appears to be float32 - if you create something with tf.zeros, tf.constant etc. it will be float32. For numpy, things often come out as float64. You need to use the function .astype(np.float32) when you create a numpy variable in order to match types\n",
    "\n",
    "\n",
    "- If you define constants using a tensorflow function e.g. input = tf.random_uniform, it will be reassigned every time you run the session. This is crucial, because in situations in which you are iteratively updating something - such as the weights in a model - anything you have randomly assigned will be REASSIGNED on every loop. This is a bad thing. To avoid this, use numpy functions to set up your constants:\n",
    "\n",
    "    input     = tf.constant(np.random.random([1]).astype(np.float32))\n",
    "    \n",
    "    \n",
    "- The only things that actually need to be placed inside the session definition (i.e. after the with tf.session() bit) are evaluations; such as initializing variables, and running loops. * If you want to re-use any of your variables from the model which are tensorflow objects, such as input, you'll need to start a sessioni nyour plotting code *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the TF gradient descent algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to alter our model to use Tensorflow's heavy lifting capabilities for model optimisation.\n",
    "\n",
    "To do this, we only need two lines:\n",
    "\n",
    "1. To tell TF what to minimise. We're going to choose the squared error\n",
    "2. To establish the optimiser, with a certain step size, with the intention of minimising the variable we created in the first step\n",
    "\n",
    "Now, we can use sess.run(ourOptimiser) to perform the optimisation!\n",
    "\n",
    "Your job here is to figure out a reasonable loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-5c927308b6a2>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-5c927308b6a2>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    loss =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Target-matching model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# we have a single input\n",
    "print \n",
    "input     = tf.constant(np.random.random([1]).astype(np.float32))\n",
    "target    = tf.constant(np.random.random([1]).astype(np.float32))\n",
    "\n",
    "alpha     = tf.constant([0.1])\n",
    "nIters    = 40\n",
    "\n",
    "totalTrack = np.zeros([nIters,1])\n",
    "# Set up two variables, total and weights, that we'll change repeatedly.\n",
    "\n",
    "weights = tf.Variable(tf.random_uniform([1]))\n",
    "\n",
    "# This only adds the operators to the graph right now. The assignment\n",
    "# and addition operations are not performed yet.\n",
    "total = tf.mul(input, weights)\n",
    "\n",
    "# *****************************************    Enter your loss function here!\n",
    "loss = \n",
    "\n",
    "# Optimizer\n",
    "ourOptimiser = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "  # Initialize the variables we defined above.\n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  for _ in range(nIters):\n",
    "    # Actually run the operation graph, so randomly generate weights and then\n",
    "    # add them into the total. Order does matter here. We need to update\n",
    "    # the weights before updating the total.\n",
    " \n",
    "\n",
    "    sess.run(ourOptimiser)\n",
    "    \n",
    "    \n",
    "    totalTrack[_]=total.eval()\n",
    "    \n",
    "    print input.eval(),weights.eval(), total.eval(), target.eval(), total.eval()-target.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final task: try plotting totalTrack to see how the output converges over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your plotting here\n",
    "\n",
    "# HINT - this plotting code should look very similar to the above plotting code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
